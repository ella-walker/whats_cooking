---
title: "whats cooking"
author: "julia nilsson"
format: html
editor: visual
---

DON"T JUST RUN THE WHOLE THING, SCROLL TO WHERE IT SAYS RUN TIL \##

```{r}
library(jsonlite)
library(tidyverse)
library(vroom)

train <- fromJSON("~/Documents/STAT 348/whats_cooking/whats-cooking/train.json")

test <- fromJSON("~/Documents/STAT 348/whats_cooking/whats-cooking/test.json")

# not unnested yet
```

```{r}
ingredient_counts <- train %>%
  unnest(ingredients) %>%
  count(ingredients, sort = TRUE)
# view(ingredient_counts)
long <- train %>% unnest(ingredients)
```

```{r}

all_cuisines <- unique(long$cuisine)

overall_counts <- long %>%
  count(ingredients, name = "count_overall")

enrichment_all <- map_dfr(all_cuisines, function(cui) {

  target_counts <- long %>%
    filter(cuisine == cui) %>%
    count(ingredients, name = "count_in_cuisine")

  left_join(target_counts, overall_counts, by = "ingredients") %>%
    mutate(
      cuisine = cui,
      ratio = count_in_cuisine / count_overall,
      weighted_count_ratio = count_in_cuisine * ratio
    ) %>%
    arrange(desc(weighted_count_ratio))
})

# View(enrichment_all)



```

```{r}
enrichment_deduplicate <- enrichment_all %>%
  group_by(ingredients) %>%
  slice_max(weighted_count_ratio, n = 1, with_ties = FALSE) %>%
  ungroup()

```

```{r}
top500 <- enrichment_deduplicate %>%
  group_by(cuisine) %>%
  arrange(desc(weighted_count_ratio)) %>%
  mutate(global_rank = row_number()) %>%
  slice_head(n = 500) %>%
  ungroup()

```

```{r}
test_long <- test %>% unnest(ingredients)
# Join test ingredients to the ranked predictors
match_table <- test_long %>%
  inner_join(top500, by = "ingredients")

best_match <- match_table %>%
  arrange(id, global_rank, cuisine) %>%   # break ties deterministically
  group_by(id) %>%
  slice(1) %>% 
  ungroup() %>%
  select(id, predicted_cuisine = cuisine)



all_cuisines <- unique(train$cuisine)

missing_ids <- setdiff(test$id, best_match$id)

random_assign <- tibble(
  id = missing_ids,
  predicted_cuisine = sample(all_cuisines, length(missing_ids), replace = TRUE)
)

final_predictions <- bind_rows(best_match, random_assign)


```

```{r}
submission <- final_predictions %>%
  arrange(id) %>%
  select(id, cuisine = predicted_cuisine)

write_csv(submission,
          "~/Documents/STAT 348/whats_cooking/preds.csv")

```

ONLY RUN TIL HERE \^\^\^\^\^

OTHER STUFF FOR FUN!!

testing to see what same-ingredient different names are significant

```{r}
recipe_flags <- trainn %>%
  mutate(
    garlic_flag = ingredients == "garlic",
    gp_flag     = ingredients == "garlic powder"
  ) %>%
  group_by(id, cuisine) %>%
  summarise(
    has_garlic = any(garlic_flag),
    has_gp     = any(gp_flag),
    has_either = has_garlic | has_gp,
    .groups = "drop"
  )

cuisine_props <- recipe_flags %>%
  filter(has_either) %>%                      # only recipes with garlic or garlic powder
  group_by(cuisine) %>%
  summarise(
    total_either = n(),
    garlic_prop  = mean(has_garlic),
    gp_prop      = mean(has_gp)
  )

cuisine_props


```

clean and turn into csv

```{r}

write_csv(train, "C:\\Users\\julia\\OneDrive - Brigham Young University\\Desktop\\stat 348\\whats-cooking\\trainscsv.csv")

write_csv(test, "C:\\Users\\julia\\OneDrive - Brigham Young University\\Desktop\\stat 348\\whats-cooking\\testcsv.csv")

```

VERY SLOW VERSION

```{r}

# train = your unnested long table
wide <- train %>%
  mutate(value = 1) %>%
  distinct(id, cuisine, ingredients, value) %>%
  pivot_wider(
    names_from = ingredients,
    values_from = value,
    values_fill = 0
  )

```

```{r}
wide <- vroom(("C:\\Users\\julia\\OneDrive - Brigham Young University\\Desktop\\stat 348\\whats-cooking\\widestcooking.csv"))
```

```{r}
library(glmnet)

# Create X and y
y <- wide$cuisine
X <- as.matrix(select(wide, -cuisine, -id))

fit <- cv.glmnet(
  X, y,
  family = "multinomial",
  alpha = 1        # LASSO
)


```

```{r}
coefs <- coef(fit, s = "lambda.min")

top_predictors <- lapply(coefs, function(mat) {
  data.frame(
    ingredient = rownames(mat),
    coef = as.numeric(mat)
  ) %>%
    filter(ingredient != "(Intercept)") %>%
    arrange(desc(abs(coef))) %>%
    slice(1:15)  # top 15 predictors
})


```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```
